---
title: Creating a Kidney Transplant Risk Calculator using GEO datasets (Group 24)

author:
  - name: 460352996 470066919 480145820 480407614

address:
  - address: GitHub code repository is [here](https://github.sydney.edu.au/aauw2900/DATA3888FinalProject)


lead_author_surname: 460352996 470066919 480145820 480407614


abstract: |
  Background- Kidney failure is the final stage of renal disease and poses a major threat to the body as the excretory system fails to function properly. To combat kidney failure patients can choose two forms of treatment in terms of medical intervention; renal dialysis or organ transplantation. Renal dialysis is used to provide some kidney functionalities by removing waste, maintaining a safe balance of potassium, sodium and bicarbonate levels in the body and helps regulate blood pressure (kidney dialysis).
  However, renal dialysis places several restrictions on the patient, compromising their quality of life and is not the ideal choice for patients with end stage kidney disease. Alternatively, organ transplantation is a life saving treatment and is greatly preferred over renal dialysis as it has the potential to offer a better quality of life for the patient posing less restrictions on diet, working lifestyle and posing fewer long term health problems. While organ transplantation greatly preferred, kidney organ allocation has posed itself as a major resource allocation problem. Donors and patients need to be matched effectively and accurately to each other to not only preserve the life of the patient but also, maximise functionality of these limited kidney organs.


# Optional: One or more keywords
keywords:
  - Transplant
  - Regression
  - Prediction
  - Immunosuppression

# Paper size for the document, values of letter and a4
papersize: a4

# Font size of the document, values of 9pt (default), 10pt, 11pt and 12pt
fontsize: 9pt

skip_final_break: true

# Optional: Bibliography 
bibliography: pinp

footer_contents: "A Research on Kidney Transplant"

# Produce a pinp document
output: pinp::pinp

vignette: >
  %\VignetteIndexEntry{YourPackage-vignetteentry}
  %\VignetteKeywords{YourPackage, r, anotherkeyword}
  %\VignettePackage{YourPackage}
  %\VignetteEngine{knitr::rmarkdown}
---
```{r, echo=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=20),tidy=TRUE)
```

```{r load_packages, include=TRUE, echo=FALSE,message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(janitor)
library("readxl")
library(ggfortify)
library(GGally)
library(qtlcharts)
library(leaps)
library(sjPlot)
library(partykit)
library(rpart)
library(caret)
library(pinp)
library(tinytex)
```

```{r app_setup, include=TRUE, echo=FALSE,message=FALSE, warning=FALSE}
library(GEOquery)
library(R.utils)
library(reshape2)
library(ggplot2)
library(limma)
library(biomaRt)
library(ggbiplot)
library(factoextra)
library(caret)
library(glmnet)
library(DESeq2)
library(edgeR)
library(DEFormats)
library(ROCR)
library(pROC)
library(doParallel)
library(foreach)
library(DescTools)
library(ggthemes)
library(class)
library(rsconnect)
library(BiocManager)
library(affy)
library(oligo)
# library(pd.mogene.2.0.st)
# library(mogene20sttranscriptcluster.db)
library(stringr)
# library(dashboardthemes)
library(survminer)
library(survival)
library(survMisc)
library(EnsDb.Hsapiens.v79)
options(repos = BiocManager::repositories())
```

## Aim and background

### Aim of the project

With this problem in mind we developed a tool to aid in the effective and  accurate allocation of donor organs to their respective patients. The developed risk calculator will assist practitioners in their decision making and shall even inform the prescriptions for immunosuppressive drugs. The risk calculator was developed with the intention that it would be used in a clinical setting where shared decision making is implemented. According to Gordan (2013), shared decision making promotes patient centered care. It permits the integration of the nephrologist’s expertise on renal allograft dysfunction with the patient’s values and beliefs concerning future treatment. Within this clinical setting, our hope would be that the risk calculator provides an opportunity of discussion that concerns the nature of treatment prior to, during and post organ transplantation.

### Multidisciplinary context

Changes being made......

### Target Audience

Should we have this here??????

## Methods

### Data collection and developed models

#### Part 1. Predicting acute rejection
Acute Rejection (AR) calculator is based on data taken from the Gene Expression Omnibus, GSE120396, GSE120649 and GSE131179. We merged the three datasets together in order to achieve a larger sample size for better accuracy, to identify outliers and provide a smaller margin of error. However, because of the differences between datasets, such as number of genes, scale (counts per million) and the use of ensembl ids rather than gene ids, we have to perform some preprocessing before they can be merged.

Inside the GSE120396, GSE120649 and GSE131179 folders are 88, 16 and 34 zipped files with file extension txt.gz respectively. Each of these files has the gene expression count for one patient. They are unzipped and placed together into a table format.

To resolve the issue of different units of measurements, we perform data standardization. In particular, cpm and log2 transformation were performed on GSE120649 and GSE131179. The ensemble id in GSE120649 and GSE131179 were converted to gene symbols using the  ‘EnsDb.Hsapiens.v79’ library from the Ensemble based annotation library from Bioconductor. 

The three datasets were joined based on common gene symbols. To account for any technical differences in gene expression measurements between the three experiments, we perform quantile normalization. Quantile normalization is one of the most widely adopted preprocessing methods for analyzing microarray data. Quantile normalization reduces batch effect and removes technological noise by scaling the variables to have values between 0 and 1, ensuring the distribution of gene expressions from each array are the same. This allowed more robust predictions that can be generalised to different sequencing platforms (Qiu et.al, 2013).

From the high dimension of gene expression data between stable and acute rejection patients, we performed feature selection using the ‘limma’ function to identify and extract the top 100 significant genes of the kidney rejection dataset. These top 100 genes were used to build a comprehensive model that can predict an acute re

Function to read in the files, unzip them, place them into a table
```{r preprocessing_function, eval=FALSE, echo=FALSE}
preprocessing_fn <- function(datadir) {
    fileNames <- list.files(datadir) # Read in the files
    
    for (files in fileNames) { # unzip
      tryCatch({
        gunzip(file.path(datadir,files))
      }, error = function(e) e)
    }
    
    # Read in all files to make a table
    result = c()
    for(i in 1:length(fileNames)){
      temptable <- read.delim(file.path(datadir, fileNames[i]), header=TRUE)
      result <- cbind(result, temptable[,2])
      colnames(result)[i] <- colnames(temptable)[2]
    }
    rownames(result) = read.delim(file.path(datadir, fileNames[1]),
                                  header=TRUE)[,1]
    
    return(result)
}
```

Preprocess data in the GSE Raw folder into a table, save it as a txt file
```{r preprocessing_part1, eval=FALSE, include=TRUE,message=FALSE, warning=FALSE}
gse_396 = preprocessing_fn("../data/GSE120396_RAW/")
write.csv(gse_396, "GSE120396_expression_matrix.txt")
```

Install the Ensembl based annotation library from Bioconductor
Function takes a GSE table as input, and returns a GSE dataframe with two new columns, 'gene symbols' and 'gene ids', from the 'ensembl ids' using the library above.
```{r convert_ensembl_function, eval=FALSE}
library("EnsDb.Hsapiens.v79")

emsembl_to_symbol <- function(gse) {
    G_list <- select(EnsDb.Hsapiens.v79,
                     key=rownames(gse), 
                     columns=c("SYMBOL"),
                     keytype="GENEID")
    df = as.data.frame(gse)
    df_symbol <- merge(df, G_list, by.x = 0,
                       by.y = 'GENEID', all.x = TRUE)
    return(df_symbol)
}
```

Log the two datasets, 649 and 179, and use the ensembl function to get the gene symbols for both datasets. Finally, merge the datasets by gene symbols.
```{r left_join_additional, eval=FALSE, message=FALSE, warning=FALSE}
# log 649!
log_649 <- log2(gse_649)
log_649[log_649 == -Inf] <- 0
df_649_symbol = emsembl_to_symbol(log_649)

# 179!
log_179 <- log2(gse_179)
log_179[log_179 == -Inf] <- 0
df_179_symbol = emsembl_to_symbol(log_179)

# left join both
df_both <- merge(df_179_symbol, df_649_symbol,
                 by.x = 'Row.names',
                 by.y = 'Row.names',
                 all.x = TRUE)
df_both
```

We plot the distribution of patient gene expression measurements using a boxplot to see if we have to remove any patient that has measurements unlike the others.
```{r 396_patients_dist, eval=FALSE}
p <- ggplot(melt(gse_396), aes(x=Var2, y=value)) +
  geom_boxplot(outlier.colour="black",
               outlier.shape=16,
               outlier.size=0.5,
               notch=FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "patient", y = "expression value") +
  theme_minimal()
p
```

#### Part 2. Estimating Time to de novo DSA Presence
The data and data dictionary used were provided by Dr. Jermaine wong.

Certain columns in the data were mutated as follows. 0 and 1 variables in the Sex_Cat columns were mapped to FEmale and Male respectively. The values in the agetxn columns were rounded and grouped into 3 categories ‘25-35’,’36-45’, and ‘46-55’. C2epletMM were also grouped into categories,’<= 30 MM’ and  ‘ > = 30MM’.

Here we first create a survival object using the Surv()  function, to which we feed in the  "C2dnDSA", "C2daystodnDSA" information, which in turn is used as the dependent variable for the Kaplan-Meier Formula. The data set is filtered by the selected user input(Age group and Gender) and passed in as the Independent variable. We plot the Kaplan Meier Curve using the survfit() function.

Based on previous research studies conducted it was found that there was no significant correlation between BMI category and graft survival (Papalia et.al, 2010) Thus we focused on only using age and gender as phenotypic information when stratifying the data to fit a particular recipient.

#### Part 3. Predicting Operational Tolerance
To predict operational tolerance, we collected the GSE22229 dataset that contained raw gene expressions from tolerant patients and normal patients (which still required immune suppression for stable graft function). GSE22229 dataset was a raw CEL dataset containing 58 zipped files, each pertaining to the gene expression for one patient that was either tolerant (19), undergoing normal immunosuppression (27), or standard controls (12). In this case, we only retained the tolerant and immunosuppressed patients for our analysis.

CEL files are data files created by the Affymetrix DNA microarray image analysis software, and contain estimated probe (sequence of DNA base pairs) intensity values extracted from biological chips called Affymetrix Genechips. Each probe was mapped to a specific gene symbol using the GPL570 Chip Description File (CDF).

Since the data is in the newer Affymetrix Arrays format (Gene ST arrays), we utilised the 'oligo' library and its functions, 'list.celfiles' and 'read.celfiles', to read a list of CEL files into our directory.  This list was then converted from an AffyBatch object into an ExpressionSet (i.e. gene expression) using the 'rma' function from the 'pd.mogene.2.0.st' library. The 'rma' function, short for Robust Multichip Average, also simultaneously log2 transforms and normalises the gene expressions.

After converting our ExpressionSet object into a dataframe, we then investigated the gene expression distribution amongst patients using a boxplot to ensure that the data has been normalised and can be used for further processing.

The boxplot above demonstrates strong similarity in gene expression between patients and so our dataframe can be further analysed without concern of batch effects between sample measurements.

After quantile normalization and batch effect removal, we performed feature selection. Firstly, genes that were lowly expressed in both groups were removed by using the filterByExpr() function from the edgeR package; these genes do not provide much biological meaning and removing them allows for less statistical tests to be performed, as well as allowing greater reliability in observing the variance between different groups (Law et al., 2018).

We then selected the top 100 most differentially expressed genes between the two groups using multiple t-tests from the `limma` package. Finally, a review by Massart et al. (2017) suggested a collection of genes that were highly differential between tolerant and normal patients, and so these were also added to our final training dataset (if they weren’t already filtered for previously).

Installing essential tac packages
```{r tac_packages, eval=FALSE, message=FALSE, warning=FALSE}
library(limma)
library(affy)
library(oligo)
library(pd.mogene.2.0.st)
library(mogene20sttranscriptcluster.db)
library(GEOquery)
```

```{r tac_processing, eval=FALSE, message=FALSE, warning=FALSE}
setwd("data/GSE22229_RAW/")
celFiles <- list.celfiles()
affyRaw <- read.celfiles(celFiles)
eset <- rma(affyRaw)

setwd("../../")
write.exprs(eset,file="tolerance.txt")
my_frame <- data.frame(exprs(eset))
write.table(my_frame,
            file="tolerance.txt",
            sep="\t")
```

### Evaluation Strategies

We decided to implement penalised logistic regression methods when creating a predictive model for Part 1 and Part 3 of our risk calculator. Logistic regression was utilised as it provides a probabilistic output for a specific risk, which may be more informative than a binary outcome. Furthermore, the penalised nature of some methods (e.g. Ridge, LASSO, Elastic Net) can address the overfitting or multicollinearity issue prevalent in large p, small n situations prevalent in gene expression data.

For Part 1 and Part 3 respectively, our model was trained using a 50-repeated 5-fold cross validation (CV) procedure. The performance of our model in predicting the CV test-set under Ridge, LASSO and Elastic Net methods were evaluated using three primary metrics: accuracy, AUC and the Brier Score.

In the case of class imbalance within the training dataset, the accuracy metric may suggest an inflated performance. As such, the AUC and Brier Score were also calculated.

* The AUC is a more robust metric with less bias to class size. Briefly, it can be thought of as the probability that a true-positive sample (e.g. AR patient) has a greater predicted risk than true-negative samples (e.g. normal patient).
  
* The Brier Score meanwhile complements the AUC by checking that the predicted risk of a sample is actually similar to the true value. For example, in a true-positive case (i.e. label = 1) with a predicted risk of 0.8, the Brier Score quantitatively measures how close the 0.8 value is to 1. Better predictions are reflected as a lower Brier Score.
  
To select our final models for Part 1 and Part 3 respectively, we quantitatively compared the accuracy, AUC and Brier Score from different penalised models (Ridge, LASSO, and Elastic Net) using boxplot visualisations.

We also evaluate the model based on robustness. Robustness refers to how well the model achieves its aim when it is applied to the general population, which is our target audience. We qualitatively analysed robustness by estimating how well the model will adjust if it is applied to real-world data, which may have potential issues such as missing information.This evaluation metric ensures the external validity of the product. 

## Results

In the final model, penalised logistic regression model is used. Logistic regression is more favourable compared to machine learning models such as random forest, as it produces a probability rather than a binary outcome. We therefore have a transparent model that produces more information for the practitioner and patient to refer to when making a decision.
 
To select the optimal number of features (i.e. genes) for our model, the CV accuracy of LASSO using the top 5 up to the top 120 most significant genes were calculated respectively. 

The highest accuracy was seen at n = 12. However, while 12 features has the best performance with an accuracy of 79%, it may not be robust when applied to real world data. In particular, it is unlikely that acute kidney rejection is caused only by the 12 genes, and it is also unlikely that all input patient data will have these 12 significant genes. 

Combined with the fact that penalised regression models can elicit further variable reduction, the choice of using 12 genes as predictors in our model may not be statistically wise. Hence, we decided to instead incorporate the top 100 most significant genes in our model, which had a CV accuracy of 77%. Indeed, while this is marginally smaller than the CV accuracy for the top 12 genes, the use of top 100 genes may be more robust

The cross-validated accuracy, AUC and Brier score of ridge, lasso and elastic net with 100 features were calculated to determine the final model. Elastic net was chosen as it has the best overall performance based on the three criterias. 

Therefore, the final model is an elastic net logistic regression model with 100 features. This model ensures a balance between accuracy and robustness, thus addressing both internal and external validity. 

### Final Model

### Deployment Process

## Discussion and Conclusion

### Potential shortcomings

### Future work and improvements

Kidney allograft transplantation as well as the study of epitope compatibility are still in its infant stages and greater research needs to be taken in order to drive scientific advancement (Tambur 2018). There also needs to be a standardisation in procedures and experimental design so that consistent results concerning the survivability can be examined and reproduced. For example, several studies that wish to determine whether BMI is a significant variable for graft rejection have demonstrated contradictory results (Papalia et.al, 2010). There is also a need for larger and more diverse datasets so that various population confounders and sources for variation can be accounted for. The diversity and larger dimensions (in terms of patient numbers) will also increase the confidence of the claims made by risk calculators and studies alike. For example, the eplet data which was used for the risk calculator consisted mostly of Caucasoid patients. This poses a class imbalance problem but more broadly speaks to which demographic and racial groups have the means to access these health services. 

### Conclusion

\newpage
## Reference List

### 1.
Dayoub, J.C. Cortese, F., Anzic, A, 2018, The Effects of Donor Age on Organ transplants: a review and implications for aging research, Experimental Gerontology, Vol 110, pp. 230-240,  Retrieved from <> 

### 2.
Dorr, C. R., Oetting, W. S., Jacobson, P. A., & Israni, A. K. (2018). Genetics of acute rejection after kidney transplantation. Transplant International, 31(3), 263-277.

### 3.
Edgar R., Domrachev M., Lash AE. (2002). Gene Expression Omnibus: NCBI gene expression and hybridization array data repository. Nucleic Acids Res, 30(1),207-10.

### 4.
Gordon, E.J., 2013, Opportunities for Shared Decision Making in Kidney Transplantation, American Journal of Transplantation, Vol.13, no.5 pp. 1149-1158.

### 5.
Kleinbaum, D.G., 2005 Klein, M., ‘Introduction to Survival Analaysis’ in Survival Analysis: A self learning text, Springer, New York, NY pp.1-43.

### 6.
Massart, A., Ghisdal, L., Abramowicz, M., & Abramowicz, D. (2017). Operational tolerance in kidney transplantation and associated biomarkers. Clinical & Experimental Immunology, 189(2), 138-157.

### 7.
Papalia, T., Greco, R., Lofaro, D., Maestripieri, S., Mancuso, D., & Bonofiglio, R. (2010). Impact of body mass index on graft loss in normal and overweight patients: retrospective analysis of 206 renal transplants. Clinical transplantation, 24(6), E241–E246. https://doi.org/10.1111/j.1399-0012.2010.01258.x

### 8.
Tambur, A.R. 2018, HLA-epitope Matching or Eplet Risk Stratification: The Devil is in the Details, Front Immunol, Vol.9

### 9.
Qiu, X., Wu, H. & Hu, R. The impact of quantile and rank normalization procedures on the testing power of gene differential expression analysis. BMC Bioinformatics 14, 124 (2013). https://doi.org/10.1186/1471-2105-14-124

## Appendixes

### Appendix A
Kaplan-Meier curve: Estimated Probability for Class II de novo DSA Appearance

```{r eplet,echo=F,message=F,warning=F,fig.height=5}
gender_input = "Male"
age_input = "36 - 45"

survdt_m = readRDS("survdt_m.rds")

load("elastic.glm.v4.Rdata")
load("backup_model_v2.Rdata")
load("100_genes.rdata")

immune_elastic = readRDS("elastic_model_immune.RDS")
train_immune = readRDS("immune_gene_final_edit.RDS")
immune_status = readRDS("immune_status.rds")
edited_immune_elastic = readRDS("edited_elastic_model_immune.RDS")


user_survdt = survdt_m %>% dplyr::filter(
  Gender == gender_input,
  Age == age_input
)

user_kmcurve <- survfit(Surv(C2daystodnDSA, C2dnDSA) ~ Eplet2MM, data = user_survdt)

legend_title <- function(gender_input, age_input) {
  legend_title = paste(gender_input, ":", age_input, "y.o.")
  return(legend_title)
}

ggsurv <- ggsurvplot(
  user_kmcurve, # survfit object with calculated statistics.
  pval = TRUE,             # show p-value of log-rank test.
  palette = c("#E7B800", "#2E9FDF"),
  caption = "Data Provided by Dr. Germain Wong (University of Sydney) \n DSA = Donor Specific Antibody \n Mm = Mismatches",
  ggtheme = theme_bw(), # customize plot and risk table with a theme.
  surv.median.line = "hv",  # add the median survival pointer.
  xlab = "Time (Years)",
  ylab = "Estimated Probability",
  subtitle = legend_title(gender_input, age_input),
  title = "Estimated Probability for Class II de novo DSA Appearance",
  font.title = c(8, "bold", "darkblue"),
  font.x = c(7, "bold", "red"),
  font.y = c(7, "bold", "darkred"),
  font.tickslab = c(7, "bold"),
  font.subtitle = c(8, "bold"),
  legend = "top",
  legend.title = "Donor Mm",
  legend.labs = c("< 30 Mm", "> 30 Mm"),
  risk.table = TRUE,       # show risk table.
  risk.table.y.text.col = T,# colour risk table text annotations.
  risk.table.height = 0.25, # the height of the risk table
  risk.table.y.text = FALSE # show bars instead of names in text annotations in legend of risk table.
)

ggsurv$plot = ggsurv$plot +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5))
ggsurv
```

### Appendix B
Penalised Logistic Regression: Risk of Acute Rejection

```{r AR,eval=F,echo=F,message=F,warning=F,fig.height=2}
mean_train<- mean(train_data_100)
inFile <- "./Patient_Data/GSM3406956_s2.txt"

#read.csv(inFile$datapath, header = input$header)
file<- read.delim(inFile, header = TRUE)

genes <- as.matrix(file[,1])
gse<- as.numeric(file[,-1])
gse<- data.matrix(gse)
rownames(gse) <- genes
counts <- gse

#getting the processed counts matrix
cpm_counts <- cpm(counts)
lcpm <- log2(cpm_counts+1)
data_counts<- normalizeQuantiles((lcpm))

#checks if ensemble id needs to be transformed

if (startsWith(genes[2], "E")){
  rownames(data_counts) = sapply(strsplit(rownames(data_counts), ".", fixed=T), function(x) x[1])
  symbols <- select(EnsDb.Hsapiens.v79, key= as.character(rownames(data_counts)), columns=c("SYMBOL"), keytype="GENEID")
  df.gse<- as.data.frame(data_counts)
  gse <- merge(df.gse, symbols, by.x = 0, by.y = 'GENEID', all.x = TRUE)
  gene_symbols<- gse[,3]
  data_counts <- as.matrix(gse[,2])
  rownames(data_counts) <- gene_symbols
}

chooseGenes <- which(!duplicated(rownames(data_counts)))
gse<- data.matrix(data_counts[chooseGenes,])

ind <- which(rownames(gse) %in% as.array(sig_genes_100))
norm_factor <- mean_train/ mean(gse[ind,]) 
df <- as.matrix(gse[ind,] * norm_factor)
df2 <- df[order(rownames(df)), ]
X = (t(df2))

#us existing models
if (length(ind)==100){
  predd_ar <- predict(elastic.glm, X, type="response")
}

#train another model
if (length(ind) != 100){
  genes_present <- rownames(as.matrix(gse[ind,]))
  ind <- which(rownames(train_data_100) %in% genes_present)
  train = as.matrix(t(train_data_100[ind,]))
  y <- ifelse(rejection_status_396_179_649=="Yes", 1,0)
  data <- data.frame(y,train)
  risk = c()
  for (i in 1:5){
    train_cont <- trainControl(method = "repeatedcv", number = 10, repeats = 5, search = "random", verboseIter = FALSE, returnData = FALSE)

    elastic_reg <- train( y~., data = data, method = "glmnet",
                          preProcess = c("center", "scale"),
                          tuneLength = 5,
                          trControl = train_cont
    )
    elastic.glm2 <- glmnet(train, y, alpha = elastic_reg$bestTune[1,1], lambda =elastic_reg$bestTune[1,2]	,  family = "binomial")
    
    predd_ar <- predict(elastic.glm2, X, type="response")
    risk[i] = predd_ar
  }
  predd_ar <- mean(risk)
}

df <- data.frame(matrix(nrow=2, ncol = 2))
names(df) <- c("variable", "percentage")
df$variable <- c("pop_risk", "pred_risk")
df$percentage <- c(0.38, predd_ar)

df <- df %>% mutate(group=ifelse(percentage <0.28, "green",
                               ifelse(percentage>=0.28 & percentage<0.48, "orange","red")),
                  label=paste0(round(percentage*100), "%"),
                  title=dplyr::recode(variable, `pop_risk`="Population Risk of Acute Rejection",
                                      `pred_risk`="Patient's Risk of Acute Rejection",
                  ))
ggplot(df, aes(fill = group, ymax = percentage, ymin = 0, xmax = 2, xmin = 1)) +
geom_rect(aes(ymax=1, ymin=0, xmax=2, xmin=1), fill ="#ece8bd") +
geom_rect() + 
coord_polar(theta = "y",start=-pi/2) + xlim(c(0, 2)) + ylim(c(0,2)) +
geom_text(aes(x = 0, y = 0, label = label, colour=group), size=4.0) +
geom_text(aes(x=0.8, y=1.45, label=title), size=2.0) + 
facet_wrap(~title, ncol = 5) +
theme_void() +
scale_fill_manual(values = c("red"="#C9146C", "orange"="#DA9112", "green"="#129188")) +
scale_colour_manual(values = c("red"="#C9146C", "orange"="#DA9112", "green"="#129188")) +
theme(strip.background = element_blank(),
      strip.text.x = element_blank()) +
guides(fill=FALSE) +
guides(colour=FALSE)+
ggtitle("Risk of Acute Rejection")+
theme(plot.title = element_text(size=12, face="bold"))+
theme(plot.title = element_text(hjust = 0.5, colour = "dark blue"))
```

### Appendix C 
Penalised Logistic Regression: Reliance on Immunosuppression

```{r immuno,eval=F,echo=F,message=F,warning=F,fig.height=2}
mean_train<- mean(as.matrix(train_immune))
inFile <- "./Patient_Data/GSM3406956_s2.txt"
file<- read.delim(inFile, header = TRUE)

genes <- as.matrix(file[,1])
gse<- as.numeric(file[,-1])
gse<- data.matrix(gse)
rownames(gse) <- genes
counts <- gse

#getting the processed counts matrix
#cpm_counts <- cpm(counts)
#lcpm <- log2(cpm_counts+1)
#data_counts<- normalizeQuantiles((lcpm))

data_counts <- counts


#checks if ensemble id needs to be transformed

if (startsWith(genes[2], "E")){
  rownames(data_counts) = sapply(strsplit(rownames(data_counts), ".", fixed=T), function(x) x[1])
  symbols <- select(EnsDb.Hsapiens.v79, key= as.character(rownames(data_counts)), columns=c("SYMBOL"), keytype="GENEID")
  df.gse<- as.data.frame(data_counts)
  gse <- merge(df.gse, symbols, by.x = 0, by.y = 'GENEID', all.x = TRUE)
  gene_symbols<- gse[,3]
  data_counts <- as.matrix(gse[,2])
  rownames(data_counts) <- gene_symbols
}

chooseGenes <- which(!duplicated(rownames(data_counts)))
gse<- data.matrix(data_counts[chooseGenes,])

ind <- which(rownames(gse) %in% as.array(rownames(train_immune)))
norm_factor <- mean_train/ mean(gse[ind,]) 
df <- as.matrix(gse[ind,] * norm_factor)
df2 <- df[order(rownames(df)), ]
X = (t(df2))

#us existing models
if (length(ind)==nrow(train_immune)){
  predd_im <- predict(immune_elastic, X, type="response")
}


#train another model
if (length(ind) != nrow(train_immune)){
  genes_present <- rownames(as.matrix(gse[ind,]))
  ind <- which(rownames(train_immune) %in% genes_present)
  train = as.matrix(t(train_immune[ind,]))
  y <- ifelse(immune_status=="Immunotherapy", 0,1)
  data <- data.frame(y,train)
  risk = c()
  for (i in 1:5){
    
    train_cont <- trainControl(method = "repeatedcv", number = 10, repeats = 5, search = "random", verboseIter = FALSE, returnData = FALSE)
    
    elastic_reg <- train( y~., data = data, method = "glmnet",
                          preProcess = c("center", "scale"),
                          tuneLength = 5,
                          trControl = train_cont
    )
    elastic.glm2 <- glmnet(train, y, alpha = elastic_reg$bestTune[1,1], lambda =elastic_reg$bestTune[1,2]	,  family = "binomial")
    
    predd_im <- predict(elastic.glm2, X, type="response")
    risk[i] = predd_im
    
  }
  
  predd_im <- mean(risk)
}

df <- data.frame(matrix(nrow=2, ncol = 2))
names(df) <- c("variable", "percentage")
df$variable <- c("pop_risk", "pred_risk")
df$percentage <- c(0.85, predd_im)

df <- df %>% mutate(group=ifelse(percentage <0.20, "green",
                               ifelse(percentage>=0.20 & percentage<0.70, "orange","red")),
                  label=paste0(round(percentage*100), "%"),
                  title=dplyr::recode(variable, `pop_risk`="Percentage of Population Relying on IS",
                                      `pred_risk`="Patient's Predicted Reliance on IS",
                  ))

ggplot(df, aes(fill = group, ymax = percentage, ymin = 0, xmax = 2, xmin = 1)) +
geom_rect(aes(ymax=1, ymin=0, xmax=2, xmin=1), fill ="#ece8bd") +
geom_rect() + 
coord_polar(theta = "y",start=-pi/2) + xlim(c(0, 2)) + ylim(c(0,2)) +
geom_text(aes(x=0, y=0, label=label, colour=group), size=4.0) +
geom_text(aes(x=0.8, y=1.45, label=title), size=2.0) + 
facet_wrap(~title, ncol = 5) +
theme_void() +
scale_fill_manual(values = c("red"="#C9146C", "orange"="#DA9112", "green"="#129188")) +
scale_colour_manual(values = c("red"="#C9146C", "orange"="#DA9112", "green"="#129188")) +
theme(strip.background = element_blank(),
      strip.text.x = element_blank()) +
guides(fill=FALSE) +
guides(colour=FALSE)+
ggtitle("Reliance on Immunosuppression (IS)")+
theme(plot.title = element_text(size=12, face="bold"))+
theme(plot.title = element_text(hjust = 0.5, colour = "dark blue"))
```

## Contribution Statement

### Johanna Jones

### Andrew Auwyang

### Eva Pu

### Niruth Bogahawatta

### Alex Wong

